{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WhatsAppChatAnalyzer:\n",
    "    def __init__(self, file_path):\n",
    "        # Download required NLTK data\n",
    "        nltk.download('punkt')\n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('wordnet')\n",
    "        nltk.download('averaged_perceptron_tagger')\n",
    "        nltk.download('punkt_tab')\n",
    "        \n",
    "        # Initialize lemmatizer\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        # Initialize Spanish and English stopwords\n",
    "        self.stop_words = set(stopwords.words('spanish') + stopwords.words('english'))\n",
    "        \n",
    "        # Custom words to ignore\n",
    "        self.ignore_words = {'image', 'video', 'omitted', 'audio', 'document'}\n",
    "        \n",
    "        # Read and parse the chat file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            self.raw_text = file.read()\n",
    "\n",
    "        # Emotional words dictionary with weights\n",
    "        self.emotional_words = {\n",
    "            'love': 1.0, 'hate': -1.0, 'miss': 0.5, 'happy': 0.8,\n",
    "            'sad': -0.8, 'excited': 0.9, 'angry': -0.9,\n",
    "            'awesome': 0.7, 'terrible': -0.7, 'good': 0.6,\n",
    "            'bad': -0.6, 'great': 0.8, 'worst': -0.8\n",
    "        }\n",
    "    \n",
    "    def parse_messages(self):\n",
    "        # Regular expression for WhatsApp message format\n",
    "        pattern = r'\\[(\\d{1,2}/\\d{1,2}/\\d{2},\\s\\d{1,2}:\\d{2}:\\d{2}\\s[AP]M)\\]\\s(.*?):\\s(.*?)(?=\\n\\[\\d{1,2}/\\d{1,2}/\\d{2}|\\Z)'\n",
    "        \n",
    "        messages = []\n",
    "        for match in re.finditer(pattern, self.raw_text, re.DOTALL):\n",
    "            timestamp_str, sender, content = match.groups()\n",
    "            \n",
    "            # Parse timestamp\n",
    "            timestamp = datetime.strptime(timestamp_str, '%m/%d/%y, %I:%M:%S %p')\n",
    "            \n",
    "            # Skip system messages\n",
    "            if 'Messages and calls are end-to-end encrypted' in content:\n",
    "                continue\n",
    "                \n",
    "            messages.append({\n",
    "                'timestamp': timestamp,\n",
    "                'sender': sender.strip(),\n",
    "                'content': content.strip(),\n",
    "                'is_media': any(word in content.lower() for word in self.ignore_words)\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(messages)\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Consolidate laughter expressions before tokenization\n",
    "        text = re.sub(r'(?i)(ha|ja|he|je){2,}|lol|lmao', 'LAUGHTER', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        \n",
    "        # Remove stopwords, ignored words, and lemmatize\n",
    "        processed_tokens = [\n",
    "            self.lemmatizer.lemmatize(token)\n",
    "            for token in tokens\n",
    "            if token.isalnum() and \n",
    "            token not in self.stop_words and \n",
    "            token not in self.ignore_words\n",
    "        ]\n",
    "        \n",
    "        return processed_tokens\n",
    "\n",
    "    def analyze_text(self, df):\n",
    "        word_timeline = defaultdict(list)\n",
    "        word_frequencies = Counter()\n",
    "        co_occurrences = defaultdict(Counter)\n",
    "        \n",
    "        # Process each message\n",
    "        for _, row in df.iterrows():\n",
    "            if not row['is_media']:\n",
    "                tokens = self.preprocess_text(row['content'])\n",
    "                \n",
    "                # Update word frequencies and timeline\n",
    "                for token in tokens:\n",
    "                    word_frequencies[token] += 1\n",
    "                    word_timeline[token].append(row['timestamp'])\n",
    "                \n",
    "                # Update co-occurrences\n",
    "                for i, token1 in enumerate(tokens):\n",
    "                    for token2 in tokens[i+1:]:\n",
    "                        co_occurrences[token1][token2] += 1\n",
    "                        co_occurrences[token2][token1] += 1\n",
    "\n",
    "        # Create the final analysis structure\n",
    "        analysis_results = {}\n",
    "        \n",
    "        for word, freq in word_frequencies.items():\n",
    "            timestamps = word_timeline[word]\n",
    "            if timestamps:\n",
    "                analysis_results[word] = {\n",
    "                    \"frequency\": freq,\n",
    "                    \"first_appearance\": min(timestamps).isoformat(),\n",
    "                    \"peak_usage\": max(timestamps).isoformat(),\n",
    "                    \"co_occurring_words\": [\n",
    "                        {\"word\": co_word, \"count\": count}\n",
    "                        for co_word, count in co_occurrences[word].most_common(5)\n",
    "                    ],\n",
    "                    \"emotional_weight\": self.calculate_emotional_weight(word)\n",
    "                }\n",
    "\n",
    "        return analysis_results\n",
    "\n",
    "    def calculate_emotional_weight(self, word):\n",
    "        # Direct emotional weight\n",
    "        weight = self.emotional_words.get(word, 0)\n",
    "        \n",
    "        # Check for partial matches (e.g., \"loving\" matches \"love\")\n",
    "        if weight == 0:\n",
    "            for emotional_word, emotional_weight in self.emotional_words.items():\n",
    "                if emotional_word in word or word in emotional_word:\n",
    "                    weight = emotional_weight * 0.8  # Slightly reduced weight for partial matches\n",
    "                    break\n",
    "        \n",
    "        return weight\n",
    "\n",
    "    def analyze_temporal_patterns(self, df):\n",
    "        # Group messages by hour and day\n",
    "        df['hour'] = df['timestamp'].dt.hour\n",
    "        df['day'] = df['timestamp'].dt.day_name()\n",
    "        \n",
    "        temporal_patterns = {\n",
    "            'hourly_activity': df['hour'].value_counts().to_dict(),\n",
    "            'daily_activity': df['day'].value_counts().to_dict(),\n",
    "            'message_density': {\n",
    "                str(date): count\n",
    "                for date, count in df.groupby(df['timestamp'].dt.date).size().items()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return temporal_patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/luz.calero/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/luz.calero/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/luz.calero/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/luz.calero/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/luz.calero/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initialize analyzer\n",
    "input_file = '_chat.txt'\n",
    "analyzer = WhatsAppChatAnalyzer(input_file)\n",
    "\n",
    "# Parse and analyze messages\n",
    "messages_df = analyzer.parse_messages()\n",
    "word_analysis = analyzer.analyze_text(messages_df)\n",
    "temporal_patterns = analyzer.analyze_temporal_patterns(messages_df)\n",
    "\n",
    "# Combine results\n",
    "analysis_results = {\n",
    "    'word_analysis': word_analysis,\n",
    "    'temporal_patterns': temporal_patterns\n",
    "}\n",
    "\n",
    "# Convert the nested dictionary to a DataFrame\n",
    "word_analysis_df = pd.DataFrame.from_dict(word_analysis, orient='index')\n",
    "\n",
    "# Expand the co_occurring_words column into separate columns\n",
    "co_occurring_expanded = pd.json_normalize(word_analysis_df['co_occurring_words'].apply(lambda x: {f\"co_word_{i+1}\": item['word'] for i, item in enumerate(x)}))\n",
    "co_occurring_counts = pd.json_normalize(word_analysis_df['co_occurring_words'].apply(lambda x: {f\"co_count_{i+1}\": item['count'] for i, item in enumerate(x)}))\n",
    "\n",
    "# Combine all DataFrames\n",
    "analysis_df = pd.concat([\n",
    "    word_analysis_df.drop('co_occurring_words', axis=1),\n",
    "    co_occurring_expanded,\n",
    "    co_occurring_counts\n",
    "], axis=1)\n",
    "\n",
    "# Convert temporal patterns to DataFrames\n",
    "hourly_df = pd.DataFrame.from_dict(temporal_patterns['hourly_activity'], orient='index', columns=['message_count'])\n",
    "hourly_df.index.name = 'hour'\n",
    "\n",
    "daily_df = pd.DataFrame.from_dict(temporal_patterns['daily_activity'], orient='index', columns=['message_count'])\n",
    "daily_df.index.name = 'day'\n",
    "\n",
    "density_df = pd.DataFrame.from_dict(temporal_patterns['message_density'], orient='index', columns=['message_count'])\n",
    "density_df.index = pd.to_datetime(density_df.index)\n",
    "density_df.index.name = 'date'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 400 Most Frequent Words:\n",
      "--------------------------------------------------------------------------------\n",
      "Word                 Frequency  Emotional Weight First Appearance         \n",
      "--------------------------------------------------------------------------------\n",
      "q                    4639       0.00            2020-10-17\n",
      "laughter             4630       0.00            2020-10-15\n",
      "u                    3118       0.00            2020-10-15\n",
      "im                   2804       0.00            2020-11-02\n",
      "si                   2325       0.00            2020-10-16\n",
      "http                 2219       0.00            2020-10-17\n",
      "omg                  2153       0.00            2020-10-18\n",
      "like                 1572       0.00            2020-11-02\n",
      "ok                   1565       0.00            2020-10-15\n",
      "sorry                1192       0.00            2020-10-20\n",
      "beba                 1163       0.00            2020-12-27\n",
      "ay                   1127       0.00            2020-10-20\n",
      "oki                  1015       0.00            2020-11-09\n",
      "sii                  943        0.00            2020-10-23\n",
      "love                 903        1.00            2020-10-28\n",
      "awww                 892        0.00            2020-10-15\n",
      "voy                  848        0.00            2020-11-02\n",
      "go                   840        0.48            2020-10-28\n",
      "also                 816        0.00            2020-10-31\n",
      "good                 803        0.60            2020-11-04\n",
      "linda                800        0.00            2020-11-03\n",
      "home                 758        0.00            2020-12-07\n",
      "bb                   718        0.00            2020-12-11\n",
      "want                 711        0.00            2020-12-07\n",
      "yes                  699        0.00            2020-11-04\n",
      "okii                 668        0.00            2020-10-15\n",
      "quiero               665        0.00            2020-10-15\n",
      "aw                   664        0.56            2020-10-16\n",
      "call                 662        0.00            2020-11-15\n",
      "get                  656        0.00            2020-11-16\n",
      "awwww                627        0.00            2020-11-03\n",
      "siii                 617        0.00            2020-10-17\n",
      "aww                  605        0.00            2020-11-04\n",
      "yeah                 593        0.00            2020-11-04\n",
      "going                588        0.00            2020-11-02\n",
      "oh                   583        0.00            2020-10-15\n",
      "ur                   579        0.00            2020-11-04\n",
      "ta                   576        0.00            2020-10-15\n",
      "time                 569        0.00            2020-10-28\n",
      "amo                  553        0.00            2020-10-24\n",
      "bien                 552        0.00            2020-10-16\n",
      "wow                  542        0.00            2020-11-23\n",
      "maybe                526        0.00            2020-10-30\n",
      "cute                 525        0.00            2020-10-15\n",
      "think                520        0.00            2020-11-04\n",
      "know                 519        0.00            2020-11-16\n",
      "quieres              516        0.00            2020-10-20\n",
      "see                  512        0.00            2020-12-22\n",
      "va                   512        0.00            2020-10-20\n",
      "one                  504        0.00            2020-10-28\n",
      "hola                 495        0.00            2020-10-15\n",
      "ma                   494        0.00            2020-11-02\n",
      "laughterj            490        0.00            2020-11-06\n",
      "yay                  483        0.00            2020-10-23\n",
      "2                    481        0.00            2020-10-17\n",
      "pq                   477        0.00            2020-11-04\n",
      "mora                 476        0.00            2020-10-19\n",
      "work                 468        0.00            2020-11-17\n",
      "pila                 462        0.00            2020-10-17\n",
      "clay                 453        0.00            2021-05-25\n",
      "feel                 452        0.00            2020-11-10\n",
      "would                452        0.00            2020-11-02\n",
      "bella                451        0.00            2020-11-30\n",
      "make                 442        0.00            2020-10-15\n",
      "w                    439        0.56            2020-12-11\n",
      "chon                 439        0.00            2020-12-23\n",
      "need                 437        0.00            2020-11-16\n",
      "1                    435        0.00            2020-10-31\n",
      "bebe                 428        0.00            2020-11-02\n",
      "back                 427        0.00            2020-12-30\n",
      "let                  425        0.00            2020-10-20\n",
      "thats                424        0.00            2020-11-06\n",
      "dnd                  418        0.00            2020-11-09\n",
      "pobre                397        0.00            2020-12-07\n",
      "come                 394        0.00            2020-11-15\n",
      "soon                 392        0.00            2020-10-31\n",
      "na                   391        0.00            2020-10-15\n",
      "ver                  391        0.00            2020-10-16\n",
      "gracias              388        0.00            2020-10-22\n",
      "toy                  385        0.00            2020-10-16\n",
      "3                    381        0.00            2020-10-31\n",
      "creo                 379        0.00            2020-10-17\n",
      "aqui                 378        0.00            2020-10-17\n",
      "fuck                 378        0.00            2020-11-28\n",
      "day                  374        0.00            2020-11-12\n",
      "way                  373        0.00            2020-10-15\n",
      "pa                   369        0.00            2020-10-17\n",
      "casa                 367        0.00            2020-12-01\n",
      "deca                 349        0.00            2020-11-16\n",
      "ill                  346        0.00            2020-11-06\n",
      "rico                 345        0.00            2020-11-02\n",
      "min                  338        0.00            2020-10-20\n",
      "dont                 335        0.00            2021-01-08\n",
      "chi                  332        0.00            2020-10-20\n",
      "still                332        0.00            2020-11-11\n",
      "nice                 331        0.00            2020-11-28\n",
      "okay                 327        0.00            2020-11-16\n",
      "look                 324        0.00            2020-11-04\n",
      "pau                  324        0.00            2022-02-12\n",
      "take                 322        0.00            2020-12-03\n",
      "awwwww               321        0.00            2020-10-20\n",
      "got                  315        0.00            2020-12-29\n",
      "dinner               314        0.00            2020-12-07\n",
      "dios                 310        0.00            2020-10-20\n",
      "ab                   309        0.00            2021-02-16\n",
      "ah                   296        0.00            2020-10-15\n",
      "hacer                294        0.00            2020-10-20\n",
      "tal                  287        0.00            2020-11-02\n",
      "ir                   286        0.00            2020-10-17\n",
      "llego                279        0.00            2020-11-04\n",
      "andrea               278        0.00            2020-11-11\n",
      "thing                276        0.00            2020-12-02\n",
      "ahora                273        0.00            2020-11-02\n",
      "chulo                269        0.00            2020-10-22\n",
      "ask                  264        0.00            2020-11-16\n",
      "much                 264        0.00            2020-11-13\n",
      "cant                 262        0.00            2020-10-20\n",
      "food                 262        0.00            2020-10-15\n",
      "andre                262        0.00            2020-11-25\n",
      "noo                  256        0.00            2020-11-09\n",
      "leave                256        0.00            2020-11-17\n",
      "okk                  255        0.00            2020-12-27\n",
      "siento               253        0.00            2020-11-15\n",
      "wtf                  251        0.00            2020-12-03\n",
      "v                    250        0.80            2021-01-13\n",
      "sara                 250        0.00            2021-03-11\n",
      "laughterjlaughter    250        0.00            2020-11-11\n",
      "asi                  247        0.00            2020-11-04\n",
      "osea                 245        0.00            2020-11-06\n",
      "4                    244        0.00            2020-10-31\n",
      "feeling              242        0.00            2020-12-30\n",
      "dio                  241        0.00            2020-10-22\n",
      "check                240        0.00            2020-12-01\n",
      "mejor                239        0.00            2020-10-20\n",
      "shit                 237        0.00            2020-11-17\n",
      "luz                  236        0.00            2020-12-29\n",
      "gon                  231        0.00            2020-10-15\n",
      "meeting              229        0.00            2020-11-06\n",
      "hoy                  229        0.00            2020-11-02\n",
      "ma√±ana               228        0.00            2020-10-30\n",
      "mishu                228        0.00            2020-11-02\n",
      "meet                 227        0.00            2020-11-12\n",
      "ahi                  227        0.00            2020-10-23\n",
      "sweet                225        0.00            2021-03-19\n",
      "tell                 224        0.00            2020-11-06\n",
      "super                224        0.00            2020-11-04\n",
      "tan                  223        0.00            2020-11-09\n",
      "sure                 222        0.00            2020-11-14\n",
      "miss                 220        0.50            2020-11-08\n",
      "5                    219        0.00            2020-11-15\n",
      "shes                 219        0.00            2020-11-06\n",
      "risa                 214        0.00            2020-11-10\n",
      "new                  213        0.00            2020-12-27\n",
      "tho                  212        0.00            2020-11-03\n",
      "wait                 211        0.00            2020-12-07\n",
      "hope                 210        0.00            2021-01-13\n",
      "k                    210        0.00            2020-12-28\n",
      "10                   210        0.00            2020-10-30\n",
      "chin                 209        0.00            2020-11-02\n",
      "isa                  208        0.00            2020-12-21\n",
      "today                208        0.00            2020-12-03\n",
      "laughterjja          206        0.00            2020-10-16\n",
      "rn                   206        0.00            2020-12-11\n",
      "ven                  205        0.00            2020-11-02\n",
      "siiii                205        0.00            2020-11-02\n",
      "puedo                204        0.00            2020-10-20\n",
      "may                  203        0.00            2020-10-31\n",
      "ooo                  201        0.00            2020-11-02\n",
      "diq                  200        0.00            2020-11-04\n",
      "late                 197        0.00            2020-10-15\n",
      "talk                 197        0.00            2021-01-13\n",
      "fun                  195        0.00            2020-11-07\n",
      "send                 194        0.00            2021-02-19\n",
      "say                  193        0.00            2021-02-19\n",
      "vamos                193        0.00            2020-10-18\n",
      "bad                  193        -0.60           2020-11-10\n",
      "well                 193        0.00            2020-10-20\n",
      "dia                  187        0.00            2020-11-23\n",
      "buy                  185        0.00            2020-11-17\n",
      "holaa                183        0.00            2020-11-19\n",
      "mimi                 181        0.00            2020-11-02\n",
      "mio                  181        0.00            2020-10-16\n",
      "date                 181        0.00            2020-12-27\n",
      "add                  181        0.00            2020-10-31\n",
      "uber                 180        0.00            2020-12-11\n",
      "said                 178        0.00            2020-12-03\n",
      "dice                 177        0.00            2020-10-22\n",
      "llamar               176        0.00            2020-12-07\n",
      "later                176        0.00            2020-11-06\n",
      "nooo                 175        0.00            2020-11-28\n",
      "hot                  175        0.00            2020-11-06\n",
      "didnt                174        0.00            2020-12-18\n",
      "made                 172        0.00            2021-01-09\n",
      "next                 170        0.00            2020-10-18\n",
      "could                170        0.00            2021-02-16\n",
      "lunch                169        0.00            2020-11-09\n",
      "lucas                168        0.00            2020-10-20\n",
      "holaaa               167        0.00            2020-12-28\n",
      "6                    167        0.00            2020-12-03\n",
      "hace                 166        0.00            2020-10-15\n",
      "stop                 165        0.00            2020-10-15\n",
      "foto                 165        0.00            2020-11-18\n",
      "right                163        0.00            2020-12-07\n",
      "night                162        0.00            2020-12-20\n",
      "friend               162        0.00            2020-12-30\n",
      "solo                 162        0.00            2020-11-02\n",
      "papa                 161        0.00            2020-12-22\n",
      "help                 161        0.00            2020-11-12\n",
      "van                  160        0.00            2020-11-17\n",
      "ahh                  159        0.00            2020-12-07\n",
      "taba                 159        0.00            2020-11-12\n",
      "crazy                158        0.00            2021-08-13\n",
      "water                158        0.00            2021-02-15\n",
      "week                 158        0.00            2020-11-11\n",
      "tofu                 157        0.00            2021-01-02\n",
      "vaina                157        0.00            2020-11-23\n",
      "happy                156        0.80            2020-11-04\n",
      "last                 156        0.00            2020-11-16\n",
      "really               156        0.00            2021-01-20\n",
      "awwwwww              155        0.00            2020-11-06\n",
      "tomorrow             155        0.00            2021-02-22\n",
      "told                 155        0.00            2020-12-28\n",
      "something            154        0.00            2020-11-17\n",
      "place                154        0.00            2020-10-31\n",
      "yayy                 154        0.00            2020-10-15\n",
      "oo                   153        0.48            2020-10-22\n",
      "tmw                  153        0.00            2020-12-07\n",
      "therapy              152        0.00            2021-01-20\n",
      "bit                  152        0.00            2021-01-13\n",
      "hora                 152        0.00            2020-12-07\n",
      "bueno                152        0.00            2020-11-02\n",
      "yea                  151        0.00            2021-02-17\n",
      "coming               150        0.00            2020-11-04\n",
      "guchta               149        0.00            2020-10-20\n",
      "weird                149        0.00            2021-02-16\n",
      "apt                  148        0.00            2020-12-07\n",
      "plan                 148        0.00            2020-12-17\n",
      "suerte               147        0.00            2020-11-02\n",
      "train                146        0.00            2020-10-28\n",
      "first                146        0.00            2020-11-07\n",
      "omfg                 145        0.00            2021-01-04\n",
      "working              145        0.00            2020-12-11\n",
      "dijo                 144        0.00            2020-11-07\n",
      "find                 144        0.00            2020-11-16\n",
      "actually             144        0.00            2020-12-07\n",
      "gabo                 143        0.00            2020-11-23\n",
      "besito               143        0.00            2020-11-02\n",
      "left                 143        0.00            2021-01-04\n",
      "order                143        0.00            2020-11-17\n",
      "ayy                  142        0.00            2020-11-03\n",
      "wanted               142        0.00            2021-02-20\n",
      "amor                 142        0.00            2020-12-24\n",
      "shower               142        0.00            2020-11-15\n",
      "even                 141        0.00            2020-12-24\n",
      "x                    141        0.72            2021-01-09\n",
      "lot                  140        0.00            2021-02-20\n",
      "sound                140        0.00            2021-01-22\n",
      "vez                  139        0.00            2020-12-03\n",
      "sleep                139        0.00            2020-12-01\n",
      "ana                  138        0.00            2020-11-28\n",
      "email                137        0.00            2020-12-11\n",
      "avisas               136        0.00            2020-10-15\n",
      "da                   136        0.00            2020-11-06\n",
      "try                  136        0.00            2020-11-17\n",
      "message              136        0.00            2021-02-18\n",
      "theyre               135        0.00            2020-11-14\n",
      "worry                135        0.00            2020-11-24\n",
      "idk                  135        0.00            2020-12-22\n",
      "manda                135        0.00            2020-12-11\n",
      "30                   135        0.00            2020-12-11\n",
      "mom                  134        0.00            2020-12-29\n",
      "top                  134        0.00            2020-12-02\n",
      "better               134        0.00            2020-10-30\n",
      "phone                134        0.00            2021-01-26\n",
      "cup                  134        0.00            2020-10-31\n",
      "getting              133        0.00            2021-01-20\n",
      "keep                 133        0.00            2020-12-02\n",
      "queria               131        0.00            2020-12-17\n",
      "tuu                  131        0.00            2021-01-01\n",
      "pls                  130        0.00            2020-12-01\n",
      "eat                  130        0.64            2021-02-19\n",
      "done                 130        0.00            2020-12-21\n",
      "gente                129        0.00            2020-12-03\n",
      "bubi                 129        0.00            2020-10-20\n",
      "thought              128        0.00            2020-12-03\n",
      "minute               127        0.00            2020-10-31\n",
      "claro                127        0.00            2020-12-22\n",
      "oil                  127        0.00            2021-01-05\n",
      "paso                 126        0.00            2020-11-13\n",
      "rica                 126        0.00            2021-01-05\n",
      "walking              125        0.00            2020-11-15\n",
      "wan                  125        0.00            2021-03-11\n",
      "sali                 124        0.00            2020-12-03\n",
      "yayyy                124        0.00            2020-11-23\n",
      "ohh                  124        0.00            2021-02-18\n",
      "llegue               124        0.00            2020-10-15\n",
      "mando                124        0.00            2020-12-22\n",
      "stacy                123        0.00            2021-03-09\n",
      "early                123        0.00            2021-01-14\n",
      "mtg                  122        0.00            2020-10-20\n",
      "excited              122        0.90            2021-02-27\n",
      "casi                 122        0.00            2020-10-20\n",
      "waiting              122        0.00            2021-01-23\n",
      "put                  121        0.00            2020-12-11\n",
      "text                 121        0.00            2021-03-15\n",
      "room                 121        0.00            2020-12-27\n",
      "drink                121        0.00            2020-10-28\n",
      "20                   120        0.00            2020-10-20\n",
      "rice                 120        0.00            2020-11-01\n",
      "mandame              120        0.00            2020-11-18\n",
      "estan                119        0.00            2020-11-07\n",
      "full                 119        0.00            2020-12-07\n",
      "sec                  119        0.00            2021-01-09\n",
      "stay                 118        0.00            2021-01-05\n",
      "flight               118        0.00            2020-12-11\n",
      "tambien              118        0.00            2020-10-23\n",
      "went                 118        0.00            2020-11-04\n",
      "demasiado            118        0.00            2020-12-22\n",
      "morning              118        0.00            2021-02-16\n",
      "puedes               118        0.00            2020-10-20\n",
      "lmk                  117        0.00            2020-11-15\n",
      "7                    116        0.00            2020-12-07\n",
      "btw                  116        0.00            2020-10-30\n",
      "mean                 116        0.00            2020-12-07\n",
      "leslie               116        0.00            2021-01-08\n",
      "walk                 116        0.00            2020-11-05\n",
      "around               116        0.00            2021-01-22\n",
      "havent               116        0.00            2020-11-30\n",
      "ready                115        0.00            2020-12-29\n",
      "coffee               114        0.00            2021-01-18\n",
      "ive                  114        0.00            2020-12-03\n",
      "sigues               114        0.00            2020-12-03\n",
      "cause                114        0.00            2020-12-22\n",
      "free                 113        0.00            2020-12-22\n",
      "bc                   113        0.00            2021-02-20\n",
      "ayyy                 113        0.00            2020-11-03\n",
      "veo                  113        0.00            2020-11-04\n",
      "asked                112        0.00            2020-11-16\n",
      "lindo                112        0.00            2020-12-24\n",
      "lindaaa              112        0.00            2020-12-23\n",
      "hi                   112        0.00            2021-02-19\n",
      "long                 111        0.00            2020-11-04\n",
      "glad                 111        0.00            2021-02-18\n",
      "covid                110        0.00            2020-10-22\n",
      "bring                110        0.00            2021-02-28\n",
      "funny                110        0.00            2020-12-24\n",
      "guch                 110        0.00            2021-05-26\n",
      "8                    110        0.00            2020-10-30\n",
      "salgo                110        0.00            2020-11-15\n",
      "15                   109        0.00            2020-11-28\n",
      "comida               109        0.00            2020-11-09\n",
      "mira                 109        0.00            2020-11-11\n",
      "eden                 109        0.00            2024-01-23\n",
      "cook                 109        0.00            2021-02-21\n",
      "fine                 109        0.00            2020-12-29\n",
      "probably             108        0.00            2020-12-22\n",
      "oooo                 108        0.00            2020-10-15\n",
      "vi                   108        0.00            2020-12-07\n",
      "ppl                  108        0.00            2020-11-17\n",
      "tonight              108        0.00            2021-01-08\n",
      "encanta              108        0.00            2020-12-24\n",
      "gusta                108        0.00            2020-11-02\n",
      "mal                  108        0.00            2020-11-04\n",
      "little               108        0.00            2021-01-20\n",
      "anything             107        0.00            2021-01-11\n",
      "luisa                107        0.00            2020-12-30\n",
      "sale                 107        0.00            2021-01-13\n",
      "linde                106        0.00            2020-12-24\n",
      "llamo                106        0.00            2020-12-11\n",
      "give                 106        0.00            2021-02-19\n",
      "ugh                  105        0.00            2020-12-22\n",
      "hago                 105        0.00            2020-11-24\n",
      "divina               105        0.00            2020-12-23\n",
      "park                 105        0.00            2020-10-18\n",
      "emily                104        0.00            2020-11-15\n",
      "plis                 104        0.00            2020-11-02\n",
      "ntp                  104        0.00            2023-01-04\n",
      "laughtera            104        0.00            2020-11-19\n",
      "lyft                 104        0.00            2020-11-04\n",
      "office               103        0.00            2021-01-19\n",
      "thinking             103        0.00            2021-03-24\n",
      "literal              103        0.00            2020-10-22\n",
      "tablespoon           103        0.00            2020-10-31\n",
      "llega                103        0.00            2021-01-04\n",
      "omw                  103        0.00            2021-05-24\n",
      "use                  103        0.00            2020-11-15\n",
      "sent                 103        0.00            2020-12-28\n",
      "salir                102        0.00            2020-10-17\n",
      "god                  102        0.00            2020-11-11\n",
      "sauce                102        0.00            2021-02-19\n",
      "bed                  102        0.00            2020-12-24\n",
      "small                101        0.00            2021-01-17\n",
      "falta                100        0.00            2020-10-20\n",
      "lado                 100        0.00            2020-11-24\n",
      "orita                100        0.00            2020-12-07\n",
      "house                100        0.00            2020-10-18\n",
      "mami                 99         0.00            2020-12-07\n",
      "found                99         0.00            2020-12-11\n",
      "sad                  99         -0.80           2020-12-29\n",
      "gram                 99         0.00            2021-11-25\n"
     ]
    }
   ],
   "source": [
    "# Print out the top 400 most frequent words in a pretty way\n",
    "# Sort and get top 400 words\n",
    "top_400_words = word_analysis_df.sort_values('frequency', ascending=False).head(400)\n",
    "\n",
    "print(\"Top 400 Most Frequent Words:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Word':<20} {'Frequency':<10} {'Emotional Weight':<15} {'First Appearance':<25}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for word, row in top_400_words.iterrows():\n",
    "    print(f\"{word:<20} {row['frequency']:<10} {row['emotional_weight']:<15.2f} {row['first_appearance'][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
